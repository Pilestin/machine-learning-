{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19060374-Kadir Emre Özer-Geri Besleme Algoritması"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmanın ileri besleme kısmı gerçeklenmiştir.Gerçek değer ve hesaplanan nöron değer(3 elemanlı dizi) arasındaki hata hesaplanmış,diğer katmanlara yayılamamıştır.Geri beslemeyi beceremediğim için sadece ilk fotoğraf için ileri besleme yapıp ağın tahminini yazdırdım."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Yollarının belirtilmesi ve yolları ile verilerin bir DataFrame içerisine alınması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn import preprocessing #Eğer bir gün \"Python iyi bir dil\" dersem beni gözünüzü kırpmadan vurunuz.-Nejat İşler \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "\n",
    "train_path = './datas/train/' \n",
    "test_path = './datas/val/' \n",
    "\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "train_df['images'] = os.listdir(train_path+'/cat') + os.listdir(train_path+'/dog') + os.listdir(train_path+'/wild') \n",
    "test_df['images'] = os.listdir(test_path+'/cat') + os.listdir(test_path+'/dog') + os.listdir(test_path+'/wild')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğitim verilerinin hazırlanması "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        images classes  \\\n",
      "0        flickr_cat_000002.jpg     cat   \n",
      "1        flickr_cat_000003.jpg     cat   \n",
      "2        flickr_cat_000004.jpg     cat   \n",
      "3        flickr_cat_000005.jpg     cat   \n",
      "4        flickr_cat_000006.jpg     cat   \n",
      "...                        ...     ...   \n",
      "14625  pixabay_wild_001249.jpg    wild   \n",
      "14626  pixabay_wild_001250.jpg    wild   \n",
      "14627  pixabay_wild_001251.jpg    wild   \n",
      "14628  pixabay_wild_001252.jpg    wild   \n",
      "14629  pixabay_wild_001253.jpg    wild   \n",
      "\n",
      "                                              path  \n",
      "0         ./datas/train//cat/flickr_cat_000002.jpg  \n",
      "1         ./datas/train//cat/flickr_cat_000003.jpg  \n",
      "2         ./datas/train//cat/flickr_cat_000004.jpg  \n",
      "3         ./datas/train//cat/flickr_cat_000005.jpg  \n",
      "4         ./datas/train//cat/flickr_cat_000006.jpg  \n",
      "...                                            ...  \n",
      "14625  ./datas/train//wild/pixabay_wild_001249.jpg  \n",
      "14626  ./datas/train//wild/pixabay_wild_001250.jpg  \n",
      "14627  ./datas/train//wild/pixabay_wild_001251.jpg  \n",
      "14628  ./datas/train//wild/pixabay_wild_001252.jpg  \n",
      "14629  ./datas/train//wild/pixabay_wild_001253.jpg  \n",
      "\n",
      "[14630 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "paths = []\n",
    "for image in train_df['images']:\n",
    "    class_ = image.split('_')[1]\n",
    "    classes.append(class_)\n",
    "    paths.append(train_path+'/'+class_+'/'+image)\n",
    "\n",
    "train_df['classes'] = classes\n",
    "train_df['path'] = paths\n",
    "print(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test verilerinin hazırlanması "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       images classes  \\\n",
      "0       flickr_cat_000008.jpg     cat   \n",
      "1       flickr_cat_000011.jpg     cat   \n",
      "2       flickr_cat_000016.jpg     cat   \n",
      "3       flickr_cat_000056.jpg     cat   \n",
      "4       flickr_cat_000076.jpg     cat   \n",
      "...                       ...     ...   \n",
      "1495  pixabay_wild_001165.jpg    wild   \n",
      "1496  pixabay_wild_001170.jpg    wild   \n",
      "1497  pixabay_wild_001184.jpg    wild   \n",
      "1498  pixabay_wild_001192.jpg    wild   \n",
      "1499  pixabay_wild_001224.jpg    wild   \n",
      "\n",
      "                                           path  \n",
      "0        ./datas/val//cat/flickr_cat_000008.jpg  \n",
      "1        ./datas/val//cat/flickr_cat_000011.jpg  \n",
      "2        ./datas/val//cat/flickr_cat_000016.jpg  \n",
      "3        ./datas/val//cat/flickr_cat_000056.jpg  \n",
      "4        ./datas/val//cat/flickr_cat_000076.jpg  \n",
      "...                                         ...  \n",
      "1495  ./datas/val//wild/pixabay_wild_001165.jpg  \n",
      "1496  ./datas/val//wild/pixabay_wild_001170.jpg  \n",
      "1497  ./datas/val//wild/pixabay_wild_001184.jpg  \n",
      "1498  ./datas/val//wild/pixabay_wild_001192.jpg  \n",
      "1499  ./datas/val//wild/pixabay_wild_001224.jpg  \n",
      "\n",
      "[1500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "paths = []\n",
    "for image in test_df['images']:\n",
    "    class_ = image.split('_')[1]\n",
    "    classes.append(class_)\n",
    "    paths.append(test_path+'/'+class_+'/'+image)\n",
    "\n",
    "test_df['classes'] = classes\n",
    "test_df['path'] = paths\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for file in train_df[\"path\"]:\n",
    "    img = cv.imread(file)\n",
    "    img = cv.resize(img, (30,30))\n",
    "    img = img.reshape(img.shape[0]*img.shape[1]*img.shape[2])\n",
    "    images.append(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katmanların Belirlenmesi ve Katman Nöron Sayıları : giriş 2700 nöron-2 ara katman (270 ve 90 nöron)-çıkış 3 nöron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = [] # 30*30*3 = 2700\n",
    "input_layer_size = 30*30*3\n",
    "\n",
    "hidden_layer_1 = [] # 30*3*3\n",
    "hidden_layer_1_size = 30*3*3\n",
    "\n",
    "hidden_layer_2 = [] # 30*3\n",
    "hidden_layer2_size = 30*3\n",
    "\n",
    "output_layer = [] # 3\n",
    "output_layer_size = 3\n",
    "\n",
    "\n",
    "def load_input_layer(i): #Giriş Katmanını yükle\n",
    "    global input_layer,images\n",
    "    input_layer = images[i]/255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katmanlar Arası Bağların Oluşturulması : Her katman bir diğerine tam bağlıdır(fully-connected).Her katmanın bir diğerine bağı matris şeklinde tanımlanmıştır.Katmanlar arası bağlar ilk başta rastgele atanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 270)\n",
      "(270, 90)\n",
      "(90, 3)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "W_Input_to_Hidden1 = np.random.randn(input_layer_size,hidden_layer_1_size) #input_layer_size x hidden_layer_1_size matrix\n",
    "W_Hidden1_to_Hidden2 = np.random.randn(hidden_layer_1_size,hidden_layer2_size)\n",
    "W_Hidden2_to_Output = np.random.randn(hidden_layer2_size,output_layer_size)\n",
    "#len(W_Hidden2_to_Output) # len(xxx) rows, len(xxx[0]) columns\n",
    "print(np.shape(W_Input_to_Hidden1))\n",
    "print(np.shape(W_Hidden1_to_Hidden2))\n",
    "print(np.shape(W_Hidden2_to_Output))\n",
    "print(np.shape(input_layer)) # 1x2700"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid İşlevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x:float):\n",
    "    return (1/(1+np.exp(-x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid'in Türevi İşlevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sigmoid(x:float):\n",
    "    return x *(1-x)\n",
    "    #return ((np.exp(-x)) / ((1 + np.exp(-x))^2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İleri Besleme İşlevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward():\n",
    "    global hidden_layer_1,hidden_layer_2,output_layer,input_layer\n",
    "    hidden_layer_1 = sigmoid(np.dot(input_layer,W_Input_to_Hidden1))\n",
    "    hidden_layer_2 = sigmoid(np.dot(hidden_layer_1,W_Hidden1_to_Hidden2))\n",
    "    output_layer = sigmoid(np.dot(hidden_layer_2,W_Hidden2_to_Output))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yapılamamış Geri Besleme İşlevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(x:int):\n",
    "    global output_error,hidden2_error,hidden1_error,input_error,output_layer,hidden_layer2,input_layer,W_Hidden2_to_Output,W_Input_to_Hidden1,W_Hidden1_to_Hidden2\n",
    "\n",
    "    if(train_df.values[x,1] == 'cat'): # Sınıfların Vektörel tanımı\n",
    "        real = [1,0,0]\n",
    "    elif(train_df.values[x,1] == 'dog'):\n",
    "        real = [0,1,0]\n",
    "    elif(train_df.values[x,1] == 'wild'):\n",
    "        real = [0,0,1]\n",
    "\n",
    "    output_error = output_layer - real #ÇIKIŞ KATMANI HATASI \n",
    "    output_delta = output_error * derivative_sigmoid(output_layer)\n",
    "    \n",
    "    hidden2_error = output_delta.dot(W_Hidden2_to_Output.T) # GİZLİ KATMAN 2 HATASI \n",
    "    hidden2_delta = hidden2_error * derivative_sigmoid(hidden_layer_2)\n",
    "\n",
    "    hidden1_error = hidden2_delta.dot(W_Hidden1_to_Hidden2.T) # GİZLİ KATMAN 1 HATASI \n",
    "    hidden1_delta = hidden1_error * (derivative_sigmoid(hidden_layer_1))\n",
    "\n",
    "    W_Input_to_Hidden1 += input_layer.T.dot(hidden1_delta)\n",
    "    W_Hidden1_to_Hidden2 += hidden_layer_1.T.dot(hidden2_delta)\n",
    "    W_Hidden2_to_Output += hidden_layer2.T.dot(output_delta)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ağın denenmesi(Sadece bir fotoğrafın alınıp ileri besleme yapılması)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9793512  0.03722832 0.00144655]\n"
     ]
    }
   ],
   "source": [
    "output_error,hidden2_error,hidden1_error,input_error = 0,0,0,0\n",
    "# for i in range (len(train_df)):\n",
    "#     load_input_layer(i)\n",
    "#     forward()\n",
    "#     back_prop(i)\n",
    "for i in range(1):\n",
    "    load_input_layer(i)\n",
    "    forward()\n",
    "    print(output_layer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "557329a2835564ac4bf9135951b6138d6314c4053862356910294b81eb71ce1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
